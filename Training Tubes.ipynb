{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUBES CNN\n",
    "\n",
    "Chandra Gilang Kencana 1103130041 Muhammad Shibgah Aulia 1301154375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from keras.backend import set_image_dim_ordering\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array, load_dataset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x /= 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(type):\n",
    "    if type is 'train' or type is 'validation' or type is 'test':\n",
    "        path = 'data/'\n",
    "        path += type\n",
    "        path += '/*.jpg'\n",
    "        set_image_dim_ordering('th')\n",
    "        x = []\n",
    "        y = []\n",
    "        for img_path in glob(path):\n",
    "            img = load_img(img_path, grayscale=True)\n",
    "            y_post = img_path.find('_') + 1\n",
    "            x.append(img_to_array(img))\n",
    "            y.append(img_path[y_post])\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x = normalize(x)\n",
    "        y = to_categorical(y, 4)\n",
    "        return x, y\n",
    "    else:\n",
    "        print('train not found\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = load_dataset('train')\n",
    "x_val, y_val = load_dataset('validation')\n",
    "\n",
    "train(x, y, x_val=x_val, y_val=y_val, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x, y, x_val=None, y_val=None, save_model=False, lr=1e-3, epoch=8, rotation_range=0.0, width_shift_range=0.0,\n",
    "          height_shift_range=0.0, horizontal_flip=True, vertical_flip=False):\n",
    "\n",
    "    model = Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Conv Layer 1 (depth 8, ukuran filter 4 x 4)  - MaxPool 1\n",
    "    model.add(Conv2D(8, (4, 4), padding='same', input_shape=x.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Conv Layer 2 (depth 16 ukuran filter 4 x 4) - MaxPool 2\n",
    "    model.add(Conv2D(16, (4, 4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Conv Layer 3 (depth 24, ukuran filter 4 x 4) - MaxPool 3\n",
    "    model.add(Conv2D(24, (4, 4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Conv Layer 4 (depth 32, ukuran filter 4 x 4) - MaxPool 4\n",
    "    model.add(Conv2D(32, (4, 4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Connected 1\n",
    "    model.add(Dense(480, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Fully Connected 2\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Sofmax Classifier\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "    dataGenerator = ImageDataGenerator(rotation_range=rotation_range, width_shift_range=width_shift_range,\n",
    "                                       height_shift_range=height_shift_range, horizontal_flip=horizontal_flip,\n",
    "                                       vertical_flip=vertical_flip)\n",
    "    dataGenerator.fit(x)\n",
    "\n",
    "# Train dan Validasi\n",
    "    model.fit_generator(dataGenerator.flow(x, y, batch_size=256), validation_data=(x_val, y_val), \n",
    "    epochs=epoch, workers=10, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model dan weight\n",
    "    if save_model:\n",
    "        model.save('model_final_fix.h5')\n",
    "        model.save_weights('weight_model_final_fix.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluasi model\n",
    "    scores = model.evaluate(x, y, verbose=0)\n",
    "    print('Hasil)\n",
    "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "    print('Nilai Validasi yang Loss : %.4f' % scores[0])\n",
    "    print('Akurasi dari Validasi : %.3f%%' % (scores[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
